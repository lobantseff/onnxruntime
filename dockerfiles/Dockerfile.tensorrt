# --------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------
# Dockerfile to run ONNXRuntime with TensorRT integration

# nVidia TensorRT Base Image
ARG TRT_CONTAINER_VERSION=22.12
FROM nvcr.io/nvidia/tensorrt:${TRT_CONTAINER_VERSION}-py3

ARG ONNXRUNTIME_REPO=https://github.com/Microsoft/onnxruntime
ARG ONNXRUNTIME_BRANCH=main
ARG CMAKE_CUDA_ARCHITECTURES=37;50;52;60;61;70;75;80

RUN apt-get update &&\
    apt-get install -y sudo git bash unattended-upgrades

RUN apt-get install -y software-properties-common \
    && add-apt-repository ppa:ubuntu-toolchain-r/test \
    && apt update \
    && apt install -y libstdc++6

RUN unattended-upgrade

RUN wget https://github.com/Kitware/CMake/releases/download/v3.27.5/cmake-3.27.5-linux-x86_64.tar.gz \
    && tar -xzvf cmake-3.27.5-linux-x86_64.tar.gz \
    && rsync -avzh cmake-3.27.5-linux-x86_64/ /usr/local/

ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:/code/cmake-3.27.3-linux-x86_64/bin:/opt/miniconda/bin:/code/onnxruntime/build/Linux/Release/:${PATH}

# Prepare onnxruntime repository & build onnxruntime with TensorRT
WORKDIR /code
RUN git clone --single-branch --branch ${ONNXRUNTIME_BRANCH} --recursive ${ONNXRUNTIME_REPO} onnxruntime
RUN /bin/sh onnxruntime/dockerfiles/scripts/install_common_deps.sh
RUN /bin/sh onnxruntime/dockerfiles/scripts/checkout_submodules.sh ${TRT_VERSION:0:3}
WORKDIR /code/onnxruntime
RUN /bin/sh build.sh --allow_running_as_root --parallel --build_shared_lib --cuda_home /usr/local/cuda --cudnn_home /usr/lib/x86_64-linux-gnu/ --use_tensorrt --tensorrt_home /usr/lib/x86_64-linux-gnu/ --config Release --build_wheel --skip_tests --skip_submodule_sync --cmake_extra_defines '"CMAKE_CUDA_ARCHITECTURES='${CMAKE_CUDA_ARCHITECTURES}'"'
RUN pip install -U pip \
    && pip install /code/onnxruntime/build/Linux/Release/dist/*.whl ipython onnx
WORKDIR /code
